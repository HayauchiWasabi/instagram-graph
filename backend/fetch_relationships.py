import json
import time
import os
import random
from curl_cffi import requests

# --- è¨­å®š ---
DATA_DIR = os.path.join(os.getcwd(), "data")
COOKIES_FILE = os.path.join(DATA_DIR, "cookies.json")
FOLLOWERS_FILE = os.path.join(DATA_DIR, "followers.json")
GRAPH_DATA_FILE = os.path.join(DATA_DIR, "graph_data.json")

# APIè¨­å®š
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "X-IG-App-ID": "936619743392459",
    "X-Requested-With": "XMLHttpRequest",
    "Referer": "https://www.instagram.com/",
}

def load_cookies():
    if not os.path.exists(COOKIES_FILE):
        print(f"ã‚¨ãƒ©ãƒ¼: {COOKIES_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚step2_dump_cookies.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    
    with open(COOKIES_FILE, "r") as f:
        selenium_cookies = json.load(f)
    
    cookie_dict = {}
    for c in selenium_cookies:
        cookie_dict[c["name"]] = c["value"]
    return cookie_dict

def load_json(filepath, default=None):
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    return default

def save_json(filepath, data):
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def fetch_mutual_followers(target_id, cookies):
    """
    æŒ‡å®šãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®å…±é€šãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã‚’APIçµŒç”±ã§å–å¾—ã™ã‚‹ (ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ)
    """
    mutuals = []
    next_max_id = ""
    page_count = 0
    base_url = f"https://www.instagram.com/api/v1/friendships/{target_id}/mutual_followers/"

    try:
        while True:
            params = {}
            if next_max_id:
                params["max_id"] = next_max_id

            # print(f"  [DEBUG] Requesting API: {base_url} (max_id={next_max_id})")
            response = requests.get(
                base_url, 
                params=params,
                cookies=cookies, 
                headers=HEADERS,
                impersonate="chrome124",
                timeout=15
            )

            if response.status_code == 200:
                data = response.json()
                users = data.get("users", [])
                # print(f"  [DEBUG] Response: Found {len(users)} users. Next Max ID: {data.get('next_max_id')}")
                
                mutuals.extend(users)
                
                next_max_id = data.get("next_max_id")
                page_count += 1
                
                if not next_max_id:
                    break
                
                time.sleep(random.uniform(1.0, 2.0))
            
            elif response.status_code == 429:
                print("âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ (429) ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚5åˆ†é–“å¾…æ©Ÿã—ã¾ã™...")
                time.sleep(300)
            elif response.status_code == 401:
                print("âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼ (401)ã€‚CookieãŒç„¡åŠ¹ã§ã™ã€‚å†å–å¾—ã—ã¦ãã ã•ã„ã€‚")
                return None
            else:
                print(f"âš ï¸ APIã‚¨ãƒ©ãƒ¼: Status {response.status_code}")
                print(response.text[:200])
                break

    except Exception as e:
        print(f"âŒ é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    return mutuals

def main():
    print("ğŸš€ é«˜é€Ÿã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ (APIç‰ˆ) ã‚’èµ·å‹•ã—ã¾ã™...")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    followers_data = load_json(FOLLOWERS_FILE)
    if not followers_data:
        print("ã‚¨ãƒ©ãƒ¼: data/followers.json ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    main_user = followers_data.get("main_user")
    followers = followers_data.get("followers", [])
    cookies = load_cookies()

    if not cookies:
        return

    # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
    graph_data = load_json(GRAPH_DATA_FILE, {
        "nodes": [{"id": main_user, "label": main_user, "group": "main"}],
        "edges": []
    })
    
    # ãƒãƒ¼ãƒ‰æƒ…å ±ã®æ•´å‚™
    existing_nodes = {node["id"] for node in graph_data["nodes"]}
    for f in followers:
        if f not in existing_nodes:
            graph_data["nodes"].append({"id": f, "label": f, "group": "follower"})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆAPIã«ã¯IDãŒå¿…è¦ãªãŸã‚ï¼‰
    # followers.json ã«IDãŒã‚ã‚Œã°è‰¯ã„ãŒã€ãªã‘ã‚Œã°APIã‹ã‚‰å¼•ãå¿…è¦ãŒã‚ã‚‹
    # ä»Šã¯IDãŒã‚ã‹ã‚‰ãªã„ã®ã§ã€searchç­‰ã¯ã›ãšã€ã²ã¨ã¾ãšIDãŒã‚ã‹ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ (mutual_followers APIã¯IDå¿…é ˆ)
    # -> å®Ÿã¯ step1 ã§å–å¾—ã—ãŸ cookies ã«ã¯è‡ªåˆ†ã®IDãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŒã€
    #    ä»–äººã®IDã‚’çŸ¥ã‚‹ã«ã¯ username -> id å¤‰æ›ãŒå¿…è¦ã€‚
    #    ã—ã‹ã— `followers.json` ã¯ username ã®ãƒªã‚¹ãƒˆã€‚
    #    APIã§ `web_profile_info` ã‚’å©ãã‹ã€æ¤œç´¢APIã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã€‚
    
    # â˜… ã“ã“ã§å•é¡Œ: username ã‹ã‚‰ user_id ã¸ã®å¤‰æ›ãŒå¿…è¦ã€‚
    # API: https://www.instagram.com/web/search/topsearch/?context=blended&query={username}
    # ã¾ãŸã¯ https://www.instagram.com/{username}/?__a=1&__d=dis
    
    print(f"å¯¾è±¡äººæ•°: {len(followers)} å")
    processed_count = 0
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®processedãƒ•ãƒ©ã‚°ã‚’ç¢ºèª
    processed_users = {node["id"] for node in graph_data["nodes"] if node.get("processed")}

    for i, follower_data in enumerate(followers):
        username = follower_data.get("username")
        user_id = follower_data.get("id")

        if not username or not user_id:
            print(f"Warning: Invalid data for index {i}. Skipping.")
            continue

        if username in processed_users:
            continue
            
        print(f"\n[{i+1}/{len(followers)}] @{username} ã®å‡¦ç†ä¸­...")

        # 1. User ID ã¯æ—¢ã«æŒã£ã¦ã„ã‚‹ã®ã§å–å¾—ä¸è¦ï¼
        
        # 2. å…±é€šãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å–å¾—
        mutual_users = fetch_mutual_followers(user_id, cookies)
        
        if mutual_users is not None:
            count = 0
            for m_user in mutual_users:
                m_username = m_user.get("username")
                # è‡ªåˆ†è‡ªèº«ã¯é™¤å¤–
                if m_username == main_user: continue
                
                # ã‚¨ãƒƒã‚¸è¿½åŠ 
                edge = {"from": username, "to": m_username}
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¯ç°¡æ˜“çš„ã«è¡Œã†ï¼ˆãƒªã‚¹ãƒˆå†…æ¤œç´¢ã¯é…ã„ãŒä»Šã¯è¨±å®¹ï¼‰
                if edge not in graph_data["edges"]:
                    graph_data["edges"].append(edge)
                    count += 1
            
            print(f"  -> {count} ä»¶ã®ç¹‹ãŒã‚Šã‚’ç™ºè¦‹")
            
            # å®Œäº†ãƒãƒ¼ã‚¯
            for node in graph_data["nodes"]:
                if node["id"] == username:
                    node["processed"] = True
            
            save_json(GRAPH_DATA_FILE, graph_data)
        
        processed_count += 1
        
        # å®‰å…¨é‹è»¢ãƒ¢ãƒ¼ãƒ‰: å¾…æ©Ÿæ™‚é–“ã‚’å¤§å¹…ã«å¢—ã‚„ã™ (15ã€œ25ç§’)
        sleep_time = random.uniform(15.0, 25.0)
        
        # 10äººã«1å›ã€ä¼‘æ†© (60ç§’)
        if processed_count % 10 == 0:
            print("  â˜• ä¼‘æ†©ä¸­ (60ç§’)...")
            sleep_time = 60
            
        # 50äººã«1å›ã€é•·ã‚ã®ä¼‘æ†© (5åˆ†)
        if processed_count % 50 == 0:
            print("  â˜• é•·ã‚ã®ä¼‘æ†© (5åˆ†)...")
            sleep_time = 300
            
        time.sleep(sleep_time)

    print("\nâœ… å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
